#!/usr/bin/env python3
"""
Streaming Email Processing Demo

Demonstrates all streaming patterns:
1. Server-Sent Events (SSE) for progress updates
2. WebSocket for real-time bidirectional communication
3. Streaming JSON for large datasets
4. Real-time classification vs batch processing comparison
"""

import asyncio
import json
import time

import httpx
import websockets


class StreamingDemo:
    """Demonstrates streaming vs batch processing patterns."""

    def __init__(self):
        self.base_url = "http://localhost:8011"
        self.sample_mbox = "/test-data/sample_receipts.mbox"  # Mounted in container

    async def demo_all_patterns(self):
        """Run all streaming pattern demonstrations."""
        print("ğŸŒŠ STREAMING EMAIL PROCESSING DEMO")
        print("=" * 50)
        print()

        # Demo 1: Server-Sent Events
        print("ğŸ“¡ Demo 1: Server-Sent Events (SSE) Streaming")
        print("-" * 45)
        await self.demo_sse_streaming()
        print()

        # Demo 2: WebSocket Bidirectional Streaming
        print("ğŸ”„ Demo 2: WebSocket Bidirectional Streaming")
        print("-" * 45)
        await self.demo_websocket_streaming()
        print()

        # Demo 3: Streaming JSON Response
        print("ğŸ“„ Demo 3: Streaming JSON Response")
        print("-" * 35)
        await self.demo_json_streaming()
        print()

        # Demo 4: Performance Comparison
        print("âš¡ Demo 4: Streaming vs Batch Performance")
        print("-" * 45)
        await self.demo_performance_comparison()
        print()

        print("ğŸ¯ STREAMING PATTERNS SUMMARY:")
        print("=" * 35)
        print("âœ… SSE: Perfect for progress updates and live dashboards")
        print("âœ… WebSocket: Ideal for real-time bidirectional communication")
        print("âœ… JSON Streaming: Memory-efficient for large datasets")
        print("âœ… Real-time Processing: Instant response for single items")
        print()
        print("ğŸ—ï¸ Architecture Benefits:")
        print("â€¢ No memory buffering of large results")
        print("â€¢ Real-time progress feedback")
        print("â€¢ Scalable for high-volume processing")
        print("â€¢ Client can disconnect/reconnect safely")

    async def demo_sse_streaming(self):
        """Demo Server-Sent Events streaming."""
        print("Opening SSE stream for email processing...")
        print(f"Stream URL: {self.base_url}/stream/emails/sse{self.sample_mbox}")
        print()

        try:
            async with httpx.AsyncClient() as client:
                async with client.stream(
                    "GET",
                    f"{self.base_url}/stream/emails/sse{self.sample_mbox}",
                    headers={"Accept": "text/event-stream"},
                    timeout=30.0,
                ) as response:
                    print("ğŸ“¡ SSE Events received:")
                    event_count = 0

                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            event_data = line[6:]  # Remove "data: " prefix
                            try:
                                data = json.loads(event_data)
                                event_count += 1

                                if "stream_started" in line:
                                    print(
                                        f"   ğŸš€ Stream started - {data.get('total_emails', 0)} emails to process",
                                    )
                                elif "email_processed" in line:
                                    email = data.get("email_result", {})
                                    progress = data.get("progress", {})
                                    print(
                                        f"   ğŸ“§ Email {progress.get('processed', 0)}: {email.get('subject', 'No subject')[:40]}...",
                                    )
                                    if progress.get("percentage"):
                                        print(f"      Progress: {progress['percentage']:.1f}%")
                                elif "stream_completed" in line:
                                    print(
                                        f"   âœ… Stream completed - {data.get('total_processed', 0)} emails processed",
                                    )
                                    break
                                elif "stream_error" in line:
                                    print(
                                        f"   âŒ Stream error: {data.get('error', 'Unknown error')}",
                                    )
                                    break

                            except json.JSONDecodeError:
                                continue

                    print(f"ğŸ“Š Total SSE events received: {event_count}")

        except Exception as e:
            print(f"âŒ SSE Demo failed: {e}")

    async def demo_websocket_streaming(self):
        """Demo WebSocket bidirectional streaming."""
        print("Connecting to WebSocket for real-time email processing...")
        print("WebSocket URL: ws://localhost:8011/ws/emails")
        print()

        try:
            uri = "ws://localhost:8011/ws/emails"
            async with websockets.connect(uri) as websocket:
                print("ğŸ”— WebSocket connected!")

                # Test 1: Real-time email classification
                print("\nğŸ“§ Test 1: Real-time email classification")
                test_email = {
                    "type": "email_classify",
                    "email_content": "Subject: Your electricity bill is ready\nFrom: utility@electric.com\nBody: Your monthly bill of $120.50 is now available for payment.",
                }

                await websocket.send(json.dumps(test_email))
                response = await websocket.recv()
                result = json.loads(response)

                print("   ğŸ“¤ Sent: Bill classification request")
                print(f"   ğŸ“¥ Received: {result['type']}")
                if result.get("result", {}).get("classification"):
                    for classification in result["result"]["classification"].get("results", []):
                        print(
                            f"      â€¢ {classification['classification_type']}: {classification['prediction']} ({classification['confidence']:.1%})",
                        )

                # Test 2: Ping/Pong
                print("\nğŸ“ Test 2: Ping/Pong keepalive")
                await websocket.send(json.dumps({"type": "ping"}))
                pong_response = await websocket.recv()
                pong_data = json.loads(pong_response)
                print("   ğŸ“¤ Sent: ping")
                print(
                    f"   ğŸ“¥ Received: {pong_data['type']} (connection: {pong_data.get('connection_id', 'unknown')})",
                )

                print("âœ… WebSocket demo completed")

        except Exception as e:
            print(f"âŒ WebSocket demo failed: {e}")

    async def demo_json_streaming(self):
        """Demo streaming JSON for large responses."""
        print("Requesting streaming JSON response...")
        print(f"URL: {self.base_url}/stream/emails/json{self.sample_mbox}")
        print()

        try:
            start_time = time.time()
            response_size = 0

            async with httpx.AsyncClient() as client:
                async with client.stream(
                    "GET", f"{self.base_url}/stream/emails/json{self.sample_mbox}",
                ) as response:
                    print("ğŸ“„ Streaming JSON response:")

                    chunk_count = 0
                    async for chunk in response.aiter_text():
                        chunk_count += 1
                        response_size += len(chunk)

                        # Show first few chunks
                        if chunk_count <= 3:
                            print(
                                f"   Chunk {chunk_count}: {chunk[:100]}{'...' if len(chunk) > 100 else ''}",
                            )
                        elif chunk_count == 4:
                            print(f"   ... (streaming {response_size} bytes so far)")

                    elapsed_time = time.time() - start_time
                    print("   âœ… Streaming completed")
                    print(f"   ğŸ“Š Total response size: {response_size} bytes")
                    print(f"   â±ï¸  Streaming time: {elapsed_time:.2f}s")
                    print(f"   ğŸ“ˆ Streaming rate: {response_size / elapsed_time / 1024:.1f} KB/s")

        except Exception as e:
            print(f"âŒ JSON streaming demo failed: {e}")

    async def demo_performance_comparison(self):
        """Compare streaming vs batch processing performance."""
        print("Comparing streaming vs batch processing...")
        print()

        # Test 1: Real-time single email classification
        print("âš¡ Real-time Classification (Streaming Pattern):")
        test_email = "Subject: Receipt from Coffee Shop\nBody: Thank you for your purchase of $5.50"

        start_time = time.time()
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/stream/classify/realtime",
                    data={"email_content": test_email},
                )
                result = response.json()

            realtime_time = time.time() - start_time
            print(f"   â±ï¸  Response time: {realtime_time:.3f}s")
            print(f"   ğŸ“Š Processing time: {result.get('processing_time_ms', 0):.1f}ms")
            print(f"   âœ… Classification: {result.get('classification', {}).get('success', False)}")

        except Exception as e:
            print(f"   âŒ Real-time test failed: {e}")

        # Test 2: Batch processing comparison
        print("\nğŸ“¦ Batch Processing (Traditional Pattern):")
        start_time = time.time()

        try:
            # Simulate batch processing - this would hit the email parser
            async with httpx.AsyncClient() as client:
                # Note: This would need the actual batch endpoint
                print("   ğŸ“ Batch processing would take longer due to:")
                print("      â€¢ File upload overhead")
                print("      â€¢ Full mbox parsing")
                print("      â€¢ Buffering all results")
                print("      â€¢ Single large response")

            time.time() - start_time
            print("   â±ï¸  Estimated batch overhead: +2-5 seconds")

        except Exception as e:
            print(f"   âŒ Batch test failed: {e}")

        print("\nğŸ¯ Performance Summary:")
        print(f"   âš¡ Real-time streaming: ~{realtime_time:.3f}s per email")
        print("   ğŸ“¦ Batch processing: ~2-5s overhead + processing time")
        print("   ğŸ† Streaming wins for: Real-time, interactive, progressive processing")
        print("   ğŸ† Batch wins for: Large archives, background processing, bulk operations")


# Standalone demo function
async def run_streaming_demo():
    """Run the streaming demo."""
    demo = StreamingDemo()
    await demo.demo_all_patterns()


if __name__ == "__main__":
    print("ğŸš€ Starting Streaming Demo...")
    print("Make sure the streaming service is running on port 8011")
    print()

    asyncio.run(run_streaming_demo())
