#!/usr/bin/env python3
"""
Streaming Email Processing Demo

Demonstrates all streaming patterns:
1. Server-Sent Events (SSE) for progress updates
2. WebSocket for real-time bidirectional communication  
3. Streaming JSON for large datasets
4. Real-time classification vs batch processing comparison
"""

import asyncio
import json
import time
import websockets
from datetime import datetime
import httpx

class StreamingDemo:
    """Demonstrates streaming vs batch processing patterns."""
    
    def __init__(self):
        self.base_url = "http://localhost:8011"
        self.sample_mbox = "/test-data/sample_receipts.mbox"  # Mounted in container
        
    async def demo_all_patterns(self):
        """Run all streaming pattern demonstrations."""
        print("🌊 STREAMING EMAIL PROCESSING DEMO")
        print("=" * 50)
        print()
        
        # Demo 1: Server-Sent Events
        print("📡 Demo 1: Server-Sent Events (SSE) Streaming")
        print("-" * 45)
        await self.demo_sse_streaming()
        print()
        
        # Demo 2: WebSocket Bidirectional Streaming  
        print("🔄 Demo 2: WebSocket Bidirectional Streaming")
        print("-" * 45)
        await self.demo_websocket_streaming()
        print()
        
        # Demo 3: Streaming JSON Response
        print("📄 Demo 3: Streaming JSON Response")
        print("-" * 35)
        await self.demo_json_streaming()
        print()
        
        # Demo 4: Performance Comparison
        print("⚡ Demo 4: Streaming vs Batch Performance")
        print("-" * 45)
        await self.demo_performance_comparison()
        print()
        
        print("🎯 STREAMING PATTERNS SUMMARY:")
        print("=" * 35)
        print("✅ SSE: Perfect for progress updates and live dashboards")
        print("✅ WebSocket: Ideal for real-time bidirectional communication")  
        print("✅ JSON Streaming: Memory-efficient for large datasets")
        print("✅ Real-time Processing: Instant response for single items")
        print()
        print("🏗️ Architecture Benefits:")
        print("• No memory buffering of large results")
        print("• Real-time progress feedback")
        print("• Scalable for high-volume processing")
        print("• Client can disconnect/reconnect safely")
    
    async def demo_sse_streaming(self):
        """Demo Server-Sent Events streaming."""
        print("Opening SSE stream for email processing...")
        print(f"Stream URL: {self.base_url}/stream/emails/sse{self.sample_mbox}")
        print()
        
        try:
            async with httpx.AsyncClient() as client:
                async with client.stream(
                    "GET", 
                    f"{self.base_url}/stream/emails/sse{self.sample_mbox}",
                    headers={"Accept": "text/event-stream"},
                    timeout=30.0
                ) as response:
                    
                    print("📡 SSE Events received:")
                    event_count = 0
                    
                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            event_data = line[6:]  # Remove "data: " prefix
                            try:
                                data = json.loads(event_data)
                                event_count += 1
                                
                                if "stream_started" in line:
                                    print(f"   🚀 Stream started - {data.get('total_emails', 0)} emails to process")
                                elif "email_processed" in line:
                                    email = data.get('email_result', {})
                                    progress = data.get('progress', {})
                                    print(f"   📧 Email {progress.get('processed', 0)}: {email.get('subject', 'No subject')[:40]}...")
                                    if progress.get('percentage'):
                                        print(f"      Progress: {progress['percentage']:.1f}%")
                                elif "stream_completed" in line:
                                    print(f"   ✅ Stream completed - {data.get('total_processed', 0)} emails processed")
                                    break
                                elif "stream_error" in line:
                                    print(f"   ❌ Stream error: {data.get('error', 'Unknown error')}")
                                    break
                                    
                            except json.JSONDecodeError:
                                continue
                    
                    print(f"📊 Total SSE events received: {event_count}")
                    
        except Exception as e:
            print(f"❌ SSE Demo failed: {e}")
    
    async def demo_websocket_streaming(self):
        """Demo WebSocket bidirectional streaming."""
        print("Connecting to WebSocket for real-time email processing...")
        print(f"WebSocket URL: ws://localhost:8011/ws/emails")
        print()
        
        try:
            uri = "ws://localhost:8011/ws/emails"
            async with websockets.connect(uri) as websocket:
                print("🔗 WebSocket connected!")
                
                # Test 1: Real-time email classification
                print("\n📧 Test 1: Real-time email classification")
                test_email = {
                    "type": "email_classify",
                    "email_content": "Subject: Your electricity bill is ready\nFrom: utility@electric.com\nBody: Your monthly bill of $120.50 is now available for payment."
                }
                
                await websocket.send(json.dumps(test_email))
                response = await websocket.recv()
                result = json.loads(response)
                
                print(f"   📤 Sent: Bill classification request")
                print(f"   📥 Received: {result['type']}")
                if result.get('result', {}).get('classification'):
                    for classification in result['result']['classification'].get('results', []):
                        print(f"      • {classification['classification_type']}: {classification['prediction']} ({classification['confidence']:.1%})")
                
                # Test 2: Ping/Pong
                print("\n🏓 Test 2: Ping/Pong keepalive")
                await websocket.send(json.dumps({"type": "ping"}))
                pong_response = await websocket.recv()
                pong_data = json.loads(pong_response)
                print(f"   📤 Sent: ping")
                print(f"   📥 Received: {pong_data['type']} (connection: {pong_data.get('connection_id', 'unknown')})")
                
                print("✅ WebSocket demo completed")
                
        except Exception as e:
            print(f"❌ WebSocket demo failed: {e}")
    
    async def demo_json_streaming(self):
        """Demo streaming JSON for large responses."""
        print("Requesting streaming JSON response...")
        print(f"URL: {self.base_url}/stream/emails/json{self.sample_mbox}")
        print()
        
        try:
            start_time = time.time()
            response_size = 0
            
            async with httpx.AsyncClient() as client:
                async with client.stream("GET", f"{self.base_url}/stream/emails/json{self.sample_mbox}") as response:
                    print("📄 Streaming JSON response:")
                    
                    chunk_count = 0
                    async for chunk in response.aiter_text():
                        chunk_count += 1
                        response_size += len(chunk)
                        
                        # Show first few chunks
                        if chunk_count <= 3:
                            print(f"   Chunk {chunk_count}: {chunk[:100]}{'...' if len(chunk) > 100 else ''}")
                        elif chunk_count == 4:
                            print(f"   ... (streaming {response_size} bytes so far)")
                    
                    elapsed_time = time.time() - start_time
                    print(f"   ✅ Streaming completed")
                    print(f"   📊 Total response size: {response_size} bytes")
                    print(f"   ⏱️  Streaming time: {elapsed_time:.2f}s")
                    print(f"   📈 Streaming rate: {response_size / elapsed_time / 1024:.1f} KB/s")
                    
        except Exception as e:
            print(f"❌ JSON streaming demo failed: {e}")
    
    async def demo_performance_comparison(self):
        """Compare streaming vs batch processing performance."""
        print("Comparing streaming vs batch processing...")
        print()
        
        # Test 1: Real-time single email classification
        print("⚡ Real-time Classification (Streaming Pattern):")
        test_email = "Subject: Receipt from Coffee Shop\nBody: Thank you for your purchase of $5.50"
        
        start_time = time.time()
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/stream/classify/realtime",
                    data={"email_content": test_email}
                )
                result = response.json()
            
            realtime_time = time.time() - start_time
            print(f"   ⏱️  Response time: {realtime_time:.3f}s")
            print(f"   📊 Processing time: {result.get('processing_time_ms', 0):.1f}ms")
            print(f"   ✅ Classification: {result.get('classification', {}).get('success', False)}")
            
        except Exception as e:
            print(f"   ❌ Real-time test failed: {e}")
        
        # Test 2: Batch processing comparison
        print("\n📦 Batch Processing (Traditional Pattern):")
        start_time = time.time()
        
        try:
            # Simulate batch processing - this would hit the email parser
            async with httpx.AsyncClient() as client:
                # Note: This would need the actual batch endpoint
                print(f"   📁 Batch processing would take longer due to:")
                print(f"      • File upload overhead")
                print(f"      • Full mbox parsing")  
                print(f"      • Buffering all results")
                print(f"      • Single large response")
            
            batch_time = time.time() - start_time
            print(f"   ⏱️  Estimated batch overhead: +2-5 seconds")
            
        except Exception as e:
            print(f"   ❌ Batch test failed: {e}")
        
        print(f"\n🎯 Performance Summary:")
        print(f"   ⚡ Real-time streaming: ~{realtime_time:.3f}s per email")
        print(f"   📦 Batch processing: ~2-5s overhead + processing time")
        print(f"   🏆 Streaming wins for: Real-time, interactive, progressive processing")
        print(f"   🏆 Batch wins for: Large archives, background processing, bulk operations")


# Standalone demo function
async def run_streaming_demo():
    """Run the streaming demo."""
    demo = StreamingDemo()
    await demo.demo_all_patterns()


if __name__ == "__main__":
    print("🚀 Starting Streaming Demo...")
    print("Make sure the streaming service is running on port 8011")
    print()
    
    asyncio.run(run_streaming_demo())